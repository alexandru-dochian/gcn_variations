{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import dataset_loader\n",
    "import utils\n",
    "import config\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "default_tensor_data_type = torch.float32\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.set_default_dtype(default_tensor_data_type)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_mapper = {\n",
    "    \"GraphUnet\": models.GraphUnet\n",
    "}\n",
    "learning_rate = 0.01\n",
    "self_loops_learning_rate = 0.1\n",
    "num_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_structure(directory_path):\n",
    "    try:\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"Directory structure created: {directory_path}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory already exists: {directory_path}\")\n",
    "\n",
    "\n",
    "def plot_and_save(fig, title, x_title, y_title, file_path):\n",
    "    fig.update_layout(title=title, xaxis_title=x_title, yaxis_title=y_title)\n",
    "    fig.write_image(file_path)\n",
    "\n",
    "\n",
    "def plot_loss_accuracy(\n",
    "    experiment_name,\n",
    "    results_target,\n",
    "    loss_train_history,\n",
    "    loss_val_history,\n",
    "    loss_test_history,\n",
    "    acc_train_history,\n",
    "    acc_val_history,\n",
    "    acc_test_history\n",
    "):\n",
    "    create_directory_structure(results_target)\n",
    "\n",
    "    # Loss Plot\n",
    "    loss_fig = go.Figure()\n",
    "    loss_fig.add_trace(go.Scatter(x=list(range(len(loss_train_history))),\n",
    "                       y=loss_train_history, mode='lines', name='Training Loss'))\n",
    "    loss_fig.add_trace(go.Scatter(x=list(range(len(loss_val_history))),\n",
    "                       y=loss_val_history, mode='lines', name='Validation Loss'))\n",
    "    loss_fig.add_trace(go.Scatter(x=list(range(len(loss_test_history))),\n",
    "                       y=loss_test_history, mode='lines', name='Test Loss'))\n",
    "\n",
    "    loss_file_path = f'{results_target}/loss_plot.png'\n",
    "    plot_and_save(loss_fig, f'[{experiment_name}] Loss',\n",
    "                  'Epoch', 'Loss', loss_file_path)\n",
    "\n",
    "    # Accuracy Plot\n",
    "    acc_fig = go.Figure()\n",
    "    acc_fig.add_trace(go.Scatter(x=list(range(len(acc_train_history))),\n",
    "                      y=acc_train_history, mode='lines', name='Training Accuracy'))\n",
    "    acc_fig.add_trace(go.Scatter(x=list(range(len(acc_val_history))),\n",
    "                      y=acc_val_history, mode='lines', name='Validation Accuracy'))\n",
    "    acc_fig.add_trace(go.Scatter(x=list(range(len(acc_test_history))),\n",
    "                      y=acc_test_history, mode='lines', name='Test Accuracy'))\n",
    "\n",
    "    acc_file_path = f'{results_target}/accuracy_plot.png'\n",
    "    plot_and_save(acc_fig, f'[{experiment_name}] Accuracy',\n",
    "                  'Epoch', 'Accuracy', acc_file_path)\n",
    "\n",
    "\n",
    "def update_csv(csv_filename, data):\n",
    "    # Check if the CSV file exists\n",
    "    try:\n",
    "        # Read the existing CSV file\n",
    "        df = pd.read_csv(csv_filename)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(\n",
    "            columns=[\n",
    "                'Experiment Name',\n",
    "                'epoch',\n",
    "                'loss_train',\n",
    "                'loss_test',\n",
    "                'loss_val'\n",
    "                'acc_train',\n",
    "                'acc_test',\n",
    "                'acc_val',\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_config: dict):\n",
    "    experiment_name = experiment_config[\"name\"]\n",
    "    model_name = experiment_config[\"model\"]\n",
    "    model_class = models_mapper[model_name]\n",
    "\n",
    "    dataset_name = experiment_config[\"dataset\"]\n",
    "\n",
    "    data = dataset_loader.load_dataset(dataset_name)\n",
    "    train_mask = data.train_mask\n",
    "    val_mask = data.val_mask\n",
    "    test_mask = data.test_mask\n",
    "    num_nodes = data.x.shape[0]\n",
    "    in_features = data.x.shape[1]\n",
    "    output_classes = len(torch.unique(data.y))\n",
    "    A = utils.create_A(data.edge_index).to(\n",
    "        device=device, dtype=default_tensor_data_type)\n",
    "    X = data.x.to(device=device, dtype=default_tensor_data_type)\n",
    "    y = data.y.to(device=device, dtype=default_tensor_data_type)\n",
    "\n",
    "    model_args = experiment_config[\"model_args\"]\n",
    "    model_args.update(\n",
    "        {\n",
    "            \"num_nodes\": num_nodes,\n",
    "            \"in_features\": in_features,\n",
    "            \"output_classes\": output_classes\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model = model_class(**model_args)\n",
    "\n",
    "    # Global optimizer\n",
    "    # Separate parameters into two groups\n",
    "    model_parameters = [param for name, param in model.named_parameters(\n",
    "    ) if \"self_loops.mask\" not in name]\n",
    "    self_loops_parameters = [\n",
    "        param for name, param in model.named_parameters() if \"self_loops.mask\" in name]\n",
    "\n",
    "    # Global optimizer\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model_parameters},\n",
    "        {'params': self_loops_parameters, 'lr': self_loops_learning_rate}\n",
    "    ], lr=learning_rate)\n",
    "\n",
    "    loss_train_history = []\n",
    "    loss_val_history = []\n",
    "    loss_test_history = []\n",
    "\n",
    "    acc_train_history = []\n",
    "    acc_val_history = []\n",
    "    acc_test_history = []\n",
    "\n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        # allow model parameters to be learned\n",
    "        model.train()\n",
    "\n",
    "        y_pred = model(X, A)\n",
    "        # we will compute the loss only with respect to train data\n",
    "        y_true_train: torch.Tensor = y[train_mask]\n",
    "        y_pred_train: torch.Tensor = y_pred[train_mask]\n",
    "        loss_train = utils.compute_loss(y_true_train, y_pred_train)\n",
    "\n",
    "        acc_train = utils.compute_accuracy(y_true_train, y_pred_train)\n",
    "        loss_train_history.append(loss_train.item())\n",
    "        acc_train_history.append(acc_train)\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        loss_train.detach()\n",
    "\n",
    "        # model performance on val/test data\n",
    "        with torch.no_grad():\n",
    "            y_true_val = y[val_mask]\n",
    "            y_pred_val = y_pred[val_mask]\n",
    "            loss_val = utils.compute_loss(y_true_val, y_pred_val)\n",
    "            acc_val = utils.compute_accuracy(y_true_val, y_pred_val)\n",
    "            loss_val_history.append(loss_val.item())\n",
    "            acc_val_history.append(acc_val)\n",
    "            loss_val.detach()\n",
    "\n",
    "            y_true_test = y[test_mask]\n",
    "            y_pred_test = y_pred[test_mask]\n",
    "\n",
    "            loss_test = utils.compute_loss(y_true_test, y_pred_test)\n",
    "            acc_test = utils.compute_accuracy(y_true_test, y_pred_test)\n",
    "            loss_test_history.append(loss_test.item())\n",
    "            acc_test_history.append(acc_test)\n",
    "            loss_test.detach()\n",
    "\n",
    "    results_target = f\"results/{experiment_name}\"\n",
    "    plot_loss_accuracy(\n",
    "        experiment_name,\n",
    "        results_target,\n",
    "        loss_train_history,\n",
    "        loss_val_history,\n",
    "        loss_test_history,\n",
    "        acc_train_history,\n",
    "        acc_val_history,\n",
    "        acc_test_history\n",
    "    )\n",
    "    last_epoch_results = {\n",
    "        'Experiment Name': experiment_name,\n",
    "        'epoch': epoch,\n",
    "        'loss_train': loss_train_history[-1],\n",
    "        'loss_test': loss_test_history[-1],\n",
    "        'loss_val': loss_val_history[-1],\n",
    "        'acc_train': acc_train_history[-1],\n",
    "        'acc_test': acc_test_history[-1],\n",
    "        'acc_val': acc_val_history[-1]\n",
    "    }\n",
    "    update_csv(\"results/overview.csv\", last_epoch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_config in config.EXPERIMENTS_CONFIG:\n",
    "    run_experiment(experiment_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
